# -*- coding: utf-8 -*-
# """rn electricidad oficial.ipynb

# Automatically generated by Colaboratory.

# Original file is located at
#     https://colab.research.google.com/drive/16gJpsPDkWzmGe_-a3tQH0LBEr4Pe3aNR
# """

#instalar para usar flask en colab
# !pip install flask-ngrok

# #celda de prueba
# from flask import Flask 
# from flask_ngrok import run_with_ngrok #sin esto no llega ala parte que te da el link



# from keras.models import model_from_json

# app = Flask(__name__) 
# run_with_ngrok(app)  #tambien importa esto  

# @app.route("/") 
# def home():  
#       # despues...
#   # carga el json y crea el modelo
#   json_file = open('model.json', 'r')
#   loaded_model_json = json_file.read()
  
#   json_file.close()
#   loaded_model = model_from_json(loaded_model_json)
#   # se cargan los pesos (weights) en el nuevo modelo
#   loaded_model.load_weights("modelo2.h5")
#   print("Modelo cargado desde el PC")
#   # se evalua el modelo cargado con los datos de los test
#   loaded_model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])
#   score = loaded_model.evaluate(X_test, y_test, verbose=0)
#   print("%s: %.2f%%" % (loaded_model.metrics_names[1], score[1]*100))
#   return print(score) #sale error con esto
#   # return "<h1>GFG is great platform to learn</h1>" #con esto si da
    
# app.run()

# # Proyecto
#   #se pone el index.html en contect/
#   #se pone el css en /content/static/css/style.css por estandar de flask
# import numpy as np
# from flask import Flask, request, jsonify, render_template
# import pickle
# import tensorflow as tf
# import numpy as np
# from tensorflow import keras
# from flask_ngrok import run_with_ngrok #importante para ejecutar aqui en colab
# # app = Flask(__name__)
# app = Flask(__name__, template_folder='/content/') #con esto recien reconoce mi archivo index.html
# # new_model = keras.models.load_model('/content/modelo2.h5')
# run_with_ngrok(app)    


# @app.route('/')
# def home():
#   import numpy as np
#   import matplotlib.pyplot as plt
#   import pandas as pd

#   # Importando los datasets
#   dataset = pd.read_csv('Churn_Modelling.csv')
#   X = dataset.iloc[:, 3:13].values
#   y = dataset.iloc[:, 13].values

#   #convertir en numerico al genero
#   labelencoder_X_2 = LabelEncoder()
#   X[:, 2] = labelencoder_X_2.fit_transform(X[:, 2])
#   X[:, 2]
#   #el pais lo vuelve 2 columnas binario(porque 2 si son 3 valores diferentes en pais?)
#   ct = ColumnTransformer([("generico", OneHotEncoder(), [1])], remainder = 'passthrough')
#   X = ct.fit_transform(X)
#   X = X[:, 1:]
#   # Escalado de Caracteristicas
#   from sklearn.preprocessing import StandardScaler
#   # sc = StandardScaler(with_mean=False)
#   # X_train = sc.fit_transform(X_train)
#   # X_test = sc.transform(X_test)

#   sc = StandardScaler(with_mean=False)
#   X_train_sc = sc.fit(X_train)
#   X_train = X_train_sc.transform(X_train)
#   X_test = X_train_sc.transform(X_test)
#   # Parte 2 - Creando Red neuronal



#   return render_template('/index.html')

# @app.route('/predict',methods=['POST'])
# def predict():
#     '''
#     For rendering results on HTML GUI
#     '''
    
#     new_model.summary()

#     #v =np.array([[19.014286,	30.396429,	204.3	,6.6,	6.6	,12	,1.16	,20	,21]])
#     v2 =np.array([[float(x) for x in request.form.values()]])
    
#     prediction = new_model.predict(v2)
#     output = prediction[0]
#     print(output[0])

#     return render_template('index.html', prediction_text='SECUELAS: Valuation Price should be Rs: {0:.2f}'.format(output[0]))

 
# def  miModelo():
#   # --------------------------------------------------------
#   from keras.models import model_from_json
#   # despues...
#   # carga el json y crea el modelo
#   json_file = open('model.json', 'r')
#   loaded_model_json = json_file.read()
#   json_file.close()
#   loaded_model = model_from_json(loaded_model_json)
#   # se cargan los pesos (weights) en el nuevo modelo
#   loaded_model.load_weights("modelo2.h5")
#   print("Modelo cargado desde el PC")
#   # se evalua el modelo cargado con los datos de los test
#   loaded_model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])
#   score = loaded_model.evaluate(X_test, y_test, verbose=0)
#   # print("%s: %.2f%%" % (loaded_model.metrics_names[1], score[1]*100))
#   print(score)
#   return score
#   # ------------------------------------------------------------

# @app.route('/predict_api',methods=['POST'])
# def predict_api():
#     '''
#     For direct API calls trought request
#     '''
#     v3 =np.array([[float(x) for x in request.form.values()]])
    
#     prediction = new_model.predict(v3)
#     output = prediction[0]
#     return jsonify(output)

# # if __name__ == "__main__":
# #     app.run()
# app.run()

# ! npm install -g localtunnel

# ! lt --port 8000

# s = pd.Series([1, 2, 1])
#     fig, ax = plt.subplots()
#     s.plot.bar()
#     fig.savefig('my_plot.png')

# from matplotlib.pyplot import figure
# import mpld3

# fig = figure()
# ax = fig.gca()
# ax.plot([1,2,3,4])

# mpld3.show(fig)

# import io
# import base64

# def fig_to_base64(fig):
#     img = io.BytesIO()
#     fig.savefig(img, format='png',
#                 bbox_inches='tight')
#     img.seek(0)

#     return base64.b64encode(img.getvalue())

# encoded = fig_to_base64(fig)
# my_html = '<img src="data:image/png;base64, {}">'.format(encoded.decode('utf-8'))

#cvs necesario
# Proyecto
  #se pone el index.html en contect/
  #se pone el css en /content/static/css/style.css por estandar de flask
import numpy as np
from flask import Flask, request, jsonify, render_template
import pickle
import tensorflow as tf
import numpy as np
from tensorflow import keras
from flask_ngrok import run_with_ngrok #importante para ejecutar aqui en colab
# app = Flask(__name__)
app = Flask(__name__, template_folder='/templates/') #con esto recien reconoce mi archivo index.html
new_model = keras.models.load_model('modeloElectricidad.h5')
run_with_ngrok(app)    


@app.route('/')
def home():
    return render_template('index.html')

@app.route('/predict',methods=['POST'])
def predict():
    '''
    For rendering results on HTML GUI
    '''
    import numpy as np
    np.set_printoptions(threshold=np.inf)
    import matplotlib.pyplot as plt
    import pandas as pd
    dataset = pd.read_csv('electricidad.csv')
    # dataset.head()
    x = dataset.iloc[:, 2:-1].values
    y = dataset.iloc[:, -1].values
    from sklearn.preprocessing import LabelEncoder
    le=LabelEncoder()
    x[:,1]= le.fit_transform(x[:,1])
    x[:,3]= le.fit_transform(x[:,3])
    x[:,5]= le.fit_transform(x[:,5])
    x[:,6]= le.fit_transform(x[:,6])
    x[:,7]= le.fit_transform(x[:,7])
    x[:,9]= le.fit_transform(x[:,9])
    #divide por rangos los datos de edades
    edades=[0,5,12,18,25,35,50,70,100]#de 0 a 5 años, de 5 a 12 años, de 12 a 18 años, de 35 a 60 años, de 60 a 100 años
    names=["1","2","3","4","5","6","7","8"]#lo que se mostrara, que nivel rango de edades esta, des 0 a 6 niveles
    x[:, 0]=pd.cut(x[:, 0],edades,labels=names)
    #divide por rangos los datos de peso
    # edades=[0,5,12,18,25,35,50,70,100]# de 0 a5, de 6 a12, de 13 a18
    pesos=[15,30,50,60,70,80,90,100]#de 0 a 5 años, de 5 a 12 años, de 12 a 18 años, de 35 a 60 años, de 60 a 100 años
    names=["1","2","3","4","5","6","7"]#lo que se mostrara, que nivel rango de edades esta, des 0 a 6 niveles
    x[:, 2]=pd.cut(x[:, 2],pesos,labels=names)
    #divide por rangos los datos de voltaje
    #   edades=[0,5,12,18,25,35,50,70,100]# de 0 a5, de 6 a12, de 13 a18
    voltaje=[0,5,10,15,30,50,80,110,200,240,380,500,1000,2000]#de 0 a 5 años, de 5 a 12 años, de 12 a 18 años, de 35 a 60 años, de 60 a 100 años
    names=["1","2","3","4","5","6","7","8","9","10","11","12","13"]#lo que se mostrara, que nivel rango de edades esta, des 0 a 6 niveles
    x[:, 4]=pd.cut(x[:, 4],voltaje,labels=names)
    #divide por rangos los datos de tiempo
    # edades=[0,5,12,18,25,35,50,70,100]# de 0 a5, de 6 a12, de 13 a18
    tiempo=[0,3,5,10,20,30,60,90,120,180,240,420]#de 0 a 5 años, de 5 a 12 años, de 12 a 18 años, de 35 a 60 años, de 60 a 100 años
    names=["1","2","3","4","5","6","7","8","9","10","11"]#lo que se mostrara, que nivel rango de edades esta, des 0 a 6 niveles
    x[:, 8]=pd.cut(x[:, 8],tiempo,labels=names)
    #divide por rangos los datos de amperios
    # edades=[0,5,12,18,25,35,50,70,100]# de 0 a5, de 6 a12, de 13 a18
    pesos=[0,10,15,25,50,200,1000,5000]#de 0 a 5 años, de 5 a 12 años, de 12 a 18 años, de 35 a 60 años, de 60 a 100 años
    names=["1","2","3","4","5","6","7"]#lo que se mostrara, que nivel rango de edades esta, des 0 a 6 niveles
    x[:, 10]=pd.cut(x[:, 10],pesos,labels=names)
    from sklearn.model_selection import train_test_split
    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)
    from sklearn.preprocessing import StandardScaler
    sc = StandardScaler()
    X_train = sc.fit_transform(X_train)
    X_test = sc.transform(X_test)
    # from sklearn.compose import ColumnTransformer
    # from sklearn.preprocessing import OneHotEncoder
    # ct = ColumnTransformer(transformers=[('encoder',OneHotEncoder(),[1])],remainder='passthrough')
    # x= np.array(ct.fit_transform(x))
    # from sklearn.model_selection import train_test_split
    # X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)
    # from sklearn.preprocessing import StandardScaler
    # sc = StandardScaler()
    # X_train = sc.fit_transform(X_train)
    # X_test = sc.transform(X_test)
    # new_model.summary()

    #v =np.array([[19.014286,	30.396429,	204.3	,6.6,	6.6	,12	,1.16	,20	,21]])
    v2 =np.array([[float(x) for x in request.form.values()]])
    print("v2:",v2)
    # prediction = new_model.predict(v2)

    import numpy 
    new_prediction = new_model.predict(sc.transform(v2))#sale 1
    # new_prediction = new_model.predict(sc.transform(v2))#sale 1
    print(new_prediction.reshape(len(new_prediction)), "->",round(len(new_prediction)))
    print("\n",new_prediction,"->>",numpy.round(new_prediction))
    # new_prediction = (new_prediction > 0.5)
    print(new_prediction)

    output = new_prediction[0]
    print("output: ", output[0])
    print("predic \ntion:", new_prediction[0])
    print(type(output[0]))
    porcentaje=np.dot(output[0],100)
    print(porcentaje)

    s = pd.Series([1, 2, 3])
    fig, ax = plt.subplots()
    s.plot.bar()
    fig.savefig('my_plot.png')

    # return render_template('articulos.html', prediction_text="valor {0}".format(output[0]))
    return render_template('index.html', prediction_text="""Probabilidad de arritmia cardiaca: {0:.0f}% 
    Resultado sin redondear: {1}""".format(porcentaje,output[0]))
    # return render_template('articulos.html', prediction_text='SECUELAS: Valuation Price should be Rs: {0:.2f} redondeado: {1:d}'.format(6,output))

@app.route('/predict_api',methods=['POST'])
def predict_api():
  
    '''
    For direct API calls trought request
    '''
    graph=df.plot(x="date",y="close")
    fig=graph.get_figure()
    filepath="graph.get_figure("
    file.savefig(filepath)
    return render_template("index.html")

# if __name__ == "__main__":
#     app.run()
# app.run()

# 1.7816945e-10*100

# "Punto flotante pi = {1: .3f}, con precisión de dígitos {1: d}" . format( 34,  3 )



# import numpy as np
# np.set_printoptions(threshold=np.inf)
# import matplotlib.pyplot as plt
# import pandas as pd
# dataset = pd.read_csv('electricidad.csv')
# # dataset.head()
# x = dataset.iloc[:, 2:-1].values
# y = dataset.iloc[:, -1].values
# from sklearn.preprocessing import LabelEncoder
# le=LabelEncoder()
# x[:,1]= le.fit_transform(x[:,1])
# x[:,3]= le.fit_transform(x[:,3])
# x[:,5]= le.fit_transform(x[:,5])
# x[:,6]= le.fit_transform(x[:,6])
# x[:,7]= le.fit_transform(x[:,7])
# x[:,9]= le.fit_transform(x[:,9])
# #divide por rangos los datos de edades
# edades=[0,5,12,18,25,35,50,70,100]#de 0 a 5 años, de 5 a 12 años, de 12 a 18 años, de 35 a 60 años, de 60 a 100 años
# names=["1","2","3","4","5","6","7","8"]#lo que se mostrara, que nivel rango de edades esta, des 0 a 6 niveles
# x[:, 0]=pd.cut(x[:, 0],edades,labels=names)
# #divide por rangos los datos de peso
# # edades=[0,5,12,18,25,35,50,70,100]# de 0 a5, de 6 a12, de 13 a18
# pesos=[15,30,50,60,70,80,90,100]#de 0 a 5 años, de 5 a 12 años, de 12 a 18 años, de 35 a 60 años, de 60 a 100 años
# names=["1","2","3","4","5","6","7"]#lo que se mostrara, que nivel rango de edades esta, des 0 a 6 niveles
# x[:, 2]=pd.cut(x[:, 2],pesos,labels=names)
# #divide por rangos los datos de voltaje
# #   edades=[0,5,12,18,25,35,50,70,100]# de 0 a5, de 6 a12, de 13 a18
# voltaje=[0,5,10,15,30,50,80,110,200,240,380,500,1000,2000]#de 0 a 5 años, de 5 a 12 años, de 12 a 18 años, de 35 a 60 años, de 60 a 100 años
# names=["1","2","3","4","5","6","7","8","9","10","11","12","13"]#lo que se mostrara, que nivel rango de edades esta, des 0 a 6 niveles
# x[:, 4]=pd.cut(x[:, 4],voltaje,labels=names)
# #divide por rangos los datos de tiempo
# # edades=[0,5,12,18,25,35,50,70,100]# de 0 a5, de 6 a12, de 13 a18
# tiempo=[0,3,5,10,20,30,60,90,120,180,240,420]#de 0 a 5 años, de 5 a 12 años, de 12 a 18 años, de 35 a 60 años, de 60 a 100 años
# names=["1","2","3","4","5","6","7","8","9","10","11"]#lo que se mostrara, que nivel rango de edades esta, des 0 a 6 niveles
# x[:, 8]=pd.cut(x[:, 8],tiempo,labels=names)
# #divide por rangos los datos de amperios
# # edades=[0,5,12,18,25,35,50,70,100]# de 0 a5, de 6 a12, de 13 a18
# pesos=[0,10,15,25,50,200,1000,5000]#de 0 a 5 años, de 5 a 12 años, de 12 a 18 años, de 35 a 60 años, de 60 a 100 años
# names=["1","2","3","4","5","6","7"]#lo que se mostrara, que nivel rango de edades esta, des 0 a 6 niveles
# x[:, 10]=pd.cut(x[:, 10],pesos,labels=names)
# from sklearn.model_selection import train_test_split
# X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)
# from sklearn.preprocessing import StandardScaler
# sc = StandardScaler()
# X_train = sc.fit_transform(X_train)
# X_test = sc.transform(X_test)
# new_prediction = new_model.predict(sc.transform(np.array([[3,1,1,1,1,1,1,1,1,1,1]])))#sale 1
# print(new_prediction.reshape(len(new_prediction)), "redondeado->",round(len(new_prediction)))
# print("\n",new_prediction,"->>>",np.round(new_prediction))
# new_prediction = (new_prediction > 0.5)
# print(new_prediction)

# #-  Edad 0-4->1 5-11->2 12-17->3 18-24->4 25-34->5  35-49->6 50-69->7 70-99o100->8
# # Sexo masculino->1 femenino->0
# # ,PesoKg 15-29->1 30-49->2 50-59->3 60-69->4 70-79->5 80-89->6 90-99o100->7
# # ,Entrada boca->0 cabeza->1 mano->2 pie->3
# # ,Voltaje 0-4->1 5-9->1 10-14->2 15-29->3 30-49->4 50-79->5 80-109->6 110-199->7 200-39->8 240-379->9 380-499->10 500-999->11 1000-1999o2000->12
# # ,TipoCorriente ac->0 dc->1
# # ,Proteccion no->0 si->1,
# # Enfermedades asma->0 cardiovascular->1 diabetes->2 epoc->3 ninguno->4 obesidad->5,
# # Tiempo 0-2->1 3-4->2 5-9->3 10-19->4 20-29->5 30-59->6 60-89->7 90-119->8 120-179->9 180-239->10 240-419o420->11   
# # ,Piel 0->humedA 1->mojada 2->seca
# # ,Amperaje 0-9->1 10-14->2 15-24->3 25-49->4 50-199->5 200-999->6 1000-4999o5000->7
# # secuela 0->no 1->si
# new_prediction = new_model.predict(sc.transform(np.array([[4, 0, 4, 1, 9, 0, 0, 0, 4, 0, 2]])))
# print(new_prediction.reshape(len(new_prediction)), "redondeado->",round(len(new_prediction)))
# print("\n",new_prediction,"->>>",np.round(new_prediction))
# new_prediction = (new_prediction > 0.5)
# print(new_prediction)

# # import numpy as np
# # np.set_printoptions(threshold=np.inf)
# # import matplotlib.pyplot as plt
# # import pandas as pd
# # dataset = pd.read_csv('Churn_Modelling.csv')
# # # dataset.head()
# # x = dataset.iloc[:, 3:-1].values
# # y = dataset.iloc[:, -1].values
# # from sklearn.preprocessing import LabelEncoder
# # le=LabelEncoder()
# # x[:,2]= le.fit_transform(x[:,2])
# # from sklearn.compose import ColumnTransformer
# # from sklearn.preprocessing import OneHotEncoder
# # ct = ColumnTransformer(transformers=[('encoder',OneHotEncoder(),[1])],remainder='passthrough')
# # x= np.array(ct.fit_transform(x))
# # from sklearn.model_selection import train_test_split
# # X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)
# # from sklearn.preprocessing import StandardScaler
# # sc = StandardScaler()
# # X_train = sc.fit_transform(X_train)
# # X_test = sc.transform(X_test)

# # import numpy 
# # new_prediction = new_model.predict(sc.transform(np.array([[1.0, 0.0, 0.0, 502,0,42,8,159660.8,3,1,0,113931.57]])))#sale 1
# # print(new_prediction.reshape(len(new_prediction)), "->",round(len(new_prediction)))
# # print("\n",new_prediction,"->",numpy.round(new_prediction))
# # new_prediction = (new_prediction > 0.5)
# # print(new_prediction)

# #graficas
# import pandas as pd
# import matplotlib.pyplot as plt
# import seaborn as sns

# datos=pd.read_csv("electricidad.csv")
# df=pd.DataFrame(datos)

# df.groupby('PesoKg')['PesoKg'].sum().plot(kind='bar', legend='Reverse')

# #graficas
# import pandas as pd
# import matplotlib.pyplot as plt
# import seaborn as sns

# datos=pd.read_csv("electricidad.csv")
# df=pd.DataFrame(datos)

# df.groupby('PesoKg')['PesoKg'].sum().plot(kind='barh', legend='Reverse')

# #graficas
# import pandas as pd
# import matplotlib.pyplot as plt
# import seaborn as sns

# datos=pd.read_csv("electricidad.csv")
# df=pd.DataFrame(datos)

# df.groupby('PesoKg')['PesoKg'].sum().plot(kind='barh', legend='Reverse')
# plt.xlabel('Suma de pesos')
# plt.ylabel('Suma')

# history_df = pd.DataFrame(new_model.history)
# history_df.loc[:, ['loss', 'accuracy',]].plot()